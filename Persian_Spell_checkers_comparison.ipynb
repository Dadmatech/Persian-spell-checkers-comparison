{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dadmatech/Persian-spell-checkers-comparison/blob/main/Persian_Spell_checkers_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir='rtl'>\n",
        "\n",
        "# ارزیابی اصلاح گر املایی فارسی\n",
        "\n",
        "\n",
        "امروزه طیف وسیعی از کاربران فارسی‌زبان اعم از دانشجویان، محققین و تولیدکنندگان محتوا با اصلاح‌گرهای املایی سروکار دارند. اصلاح‌گر املایی چنان‌چه عملکرد مطلوبی ارائه دهد،  هم فرایند نگارش را تسریع نموده و هم کیفیت متن نهایی را ارتقا می‌بخشد. به‌رغم معرفی و توسعه چندین اصلاح‌گر املایی مختص به فارسی در سال‌های اخیر، اطلاعات جامع و قابل‌اتکایی از کیفیت هریک و به‌خصوص در قیاس با یکدیگر در دست نیست. این امر ما را برآن داشت تا با جمع‌آوری و تهیه دادگان ارزیابی استاندارد و متنوع، اصلاح‌گرهای املایی مشهور موجود در زبان فارسی را در بوته آزمایش قرار داده و نتایج را به‌تفکیک و با شرح توضیحات لازم، به‌صورت عمومی منتشر سازیم. امید داریم ماحصل این تلاش، هم کاربران را در گزینش اصلاح‌گر املایی دلخواه یاری رساند و هم توسعه‌دهندگان این دست محصولات را بیش از پیش، نسبت به کیفیت محصول خود و محصولات مشابه آگاهی بخشد.\n",
        "\n",
        "\n",
        "\n",
        "## دادگان ارزیابی\n",
        "\n",
        "\n",
        "بررسی‌های صورت‌گرفته  در راستای یافتن دادگان ارزیابی مناسب، آخرسر سه دادگان ذره‌بین، PerSpellData  و شرق را پیش‌روی ما نهاد. باتوجه به ضعف‌های هریک از این دادگان که در ادامه بیان خواهد شد، دو مجموعه دادگان جدید نیز توسط تیم ما ساخته و به‌کارگرفته شد. جزئیات آماری هریک از این دادگان، در جدول زیر قابل مشاهده است.\n",
        "\n",
        "- **دادگان ذره‌بین**: مجموعه‌ای از ۱۰۳۳ زوج عبارت صحیح و عبارت دارای خطا از سرچ‌های کاربران سامانه ذره‌بین همراه اول\n",
        "\n",
        "- **دادگان ارزیابی PerSpellData**: مجموعه‌داده‌ی ارزیابی معرفی شده در مقاله‌ی PerSpellData * شامل ۱۱۲۷ زوج عبارت صحیح و عبارت دارای خطا\n",
        "\n",
        "\n",
        "> PerSpellData: An Exhaustive Parallel Spell Dataset For Persian, 2021\n",
        "\n",
        "- **دادگان شرق** -\n",
        "شامل ۲۲۳ زوج عبارت صحیح و عبارت دارای خطا\n",
        "تهیه شده توسط دکتر ممتازی\n",
        "\n",
        "- **مجموعه دادگان نویسه**\n",
        ": یکی از روش‌های نوین در ساخت زوج دادگان املایی، روش خودکار و مبتنی بر اعمال نویز است. بر اساس این رویکرد، دادگان نویسه تولید شده و در این ارزیابی نیز مورد استفاده قرار گرفته است. در  ساخت این دادگان کوشیده‌ایم، انواع و اقسام خطاهای محتمل املایی را پوشش دهیم. علاوه بر این، عوامل اثرگذاری هم‌چون جایگاه حروف در صفحه کلیدهای فارسی، حروف هم‌آوا، حروف هم‌شکل و غلط‌های مصطلح را نیز تا حد امکان در ساخت دادگان دخیل نموده‌ایم. نکته پایانی هم آن‌که ماده خام این دادگان، آخرین خبرهای خزش‌شده از صفحات خبری فارسی بوده تا احتمال هم‌پوشانی دادگان ارزیابی با دادگان آموزش اصلاح‌گرهای املایی به حداقل برسد. \n",
        "\n",
        ">  ۱.**دادگانی از جملات متن‌های خبری**\n",
        "\n",
        "> ۲.**دادگان عنوان خبرها**\n",
        "\n",
        "> ۳. **دادگان عنوان خبر - ۵۳۹**\n",
        "دادگان کوچک‌تری که از ۵۳۹ رکورد اول دادگان عنوان‌ خبرهای درست‌ست تعریف شده است تا  ارزیابی آن دسته از اصلاح‌گرهای املایی که نیاز به اعمال دستی دارند تسهیل شود.\n",
        "\n",
        "اطلاعات کلی مجموعه دادگان یاد شده:\n",
        "\n",
        "| نام دادگان‌ | تعداد جمله‌ها | میانگین تعداد کلمات در جمله | تعداد خطا | میانگین خطا در جمله | دانلود |\n",
        "| -- | -- | -- | -- | -- | -- |\n",
        "| **دادگان  ذره‌بین** | ۱۰۳۳ | ۳.۵۴ | ۱۴۰۷ | ۱.۳۶| [لینک](https://drive.google.com/drive/folders/1PofK9ASp6TJ7Q-DZKUmPfLd8zabWHKFo?usp=sharing)|\n",
        "| **دادگان PerSpellData** | ۱۱۲۷ | ۱۲.۹ | ۱۱۵۷ | ۱.۰۲ | [لینک](https://drive.google.com/drive/folders/1v-Zz5D1SceFumVHEz49P-l4-1yfysiyx?usp=sharing) |\n",
        "| **دادگان شرق** | ۲۲۳ | ۸.۵۱ | ۲۲۲ | ۰.۹۹ | [لینک](https://drive.google.com/drive/folders/1n3STWIfY7bfTek7OMJPuzJI51op3EpfL?usp=sharing) |\n",
        "| **دادگان نویسه - متن خبر** | ۴۵۱ | ۲۴.۷۶ | ۲۳۰۵ | ۵.۱۱ | [لینک گیت‌هاب](https://github.com/Dadmatech/Nevise-Dataset/tree/main/nevise-news-451) |\n",
        "|  **دادگان نویسه - عنوان خبر -  ۵۳۹**|  ۵۳۹ | ۱۰.۰۲ | ۵۱۰ | ۰.۹۴ | [لینک گیت‌هاب](https://github.com/Dadmatech/Nevise-Dataset/tree/main/nevise-news-title-539) |\n",
        "| **دادگان نویسه - عنوان خبر** | ۱۹۴۲۱ | ۱۰.۲۱ | ۱۸۳۶۸ | ۰.۹۴ | [لینک گیت‌هاب](https://github.com/Dadmatech/Nevise-Dataset/tree/main/nevise-news-title-all) |\n",
        "\n",
        "\n",
        "### چالش‌های مجموعه‌ها\n",
        "\n",
        "- ذره‌بین: این دادگان منحصر به جست‌وجوهای کاربران بوده و بنابراین برای فرم‌های دیگری از متن مانند متون بلند  محک مناسبی به‌شمار نمی‌رود.\n",
        "\n",
        "- دادگان شرق: حجم اندک این دادگان، نقطه‌ضعف اصلی آن محسوب می‌شود.\n",
        "\n",
        "- پراسپل‌دیتا-تست‌ست: این دادگان، اگرچه غلط‌های مصطلح را  مدنظر قرار داده اما از تنوع بسیار کمی برخوردار است. برای مثال در  ۵ رکورد اول این دادگان خطای یکتا وجود دارد.\n",
        "\n",
        "| ردیف | جمله |\n",
        "| -- | -- |\n",
        "| ۱ | مرادی با اشاره به آبات قرآن که خداوند می‌فرماید  |\n",
        "| ۲ | قرآن راه سعادت آبات قرآن و احادیث مرتبط آیه‌های قرآنی و فرهنگ مسلمانی و سعادت در خانه بسیار قرآن خوانده شود |\n",
        "| ۳‌ | و حتی آبات قرآن را هم می‌دونستم |\n",
        "| ۴ | همان بیتی که آبات نور الهی در آن نازل گردیده |\n",
        "| ۵‌ | و خداوند تعلل و کوتاهی و سهل انگاری در این زمینه را طبق صریح آبات قرآن و متون دینی صحیح ذیربط از ما نخواهد بخشید |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## معیارهای ارزیابی\n",
        "\n",
        "مرحله‌ی بعدی معرفی معیارهایی برای سنجش است. معمولا نرخ تشخیص خطا و نرخ اصلاح واژه‌‌ها می‌توانند مهمترین معیار باشند اما نرخ واژه‌های صحیحی که غلط تشخیص داده‌می‌شوند نیز از اهمیت بالایی برخوردار است. به همین دلیل معیار precision با توجه به مسئله تعریف می‌شود. \n",
        "\n",
        " نحوه‌ی محاسبه‌ی معیارها:\n",
        "\n",
        "\n",
        "> **wrongs**: تعداد غلط‌های نوشته\n",
        "\n",
        "> **detected**: تعداد غلط‌های کشف‌شده توسط الگوریتم\n",
        "\n",
        "> **c2c**: تعداد کلمات صحیحی که دست‌نخورده باقی‌ماندند\n",
        "\n",
        "> **w2c**: تعداد غلط‌هایی که تصحیح شدند\n",
        "\n",
        "> **c2w**: تعداد کلمات صحیحی که تخریب شدند\n",
        "\n",
        "> **w2w**: تعداد کلمات غلطی که با کلمه‌ی اشتباه دیگری جایگزین شدند\n",
        "\n",
        "\n",
        "-  نرخ کشف خطا\n",
        " (Recall)\n",
        "\n",
        "$$\\frac{detected}{wrongs}$$\n",
        "\n",
        "- نرخ صحت کشف خطاها\n",
        "(Precision)\n",
        "\n",
        "$$\\frac{w2c + w2w}{c2w + w2c + w2w}$$\n",
        "\n",
        "\n",
        "\n",
        "- نرخ اصلاح واژه‌های خطا\n",
        "\n",
        "$$\\frac{w2c}{wrongs}$$\n",
        "\n",
        "- نرخ تخریب واژه‌های صحیح\n",
        "\n",
        "$$\\frac{c2w}{w2c + c2c}$$\n",
        "\n",
        "\n",
        "\n",
        "## نحوه‌ی ارزیابی اصلاح‌گرهای املایی\n",
        " \n",
        "- **اصلاح‌گر املایی گوگل** در پیشنهاد‌های google doc برای جایگزینی واژه‌‌ها دیده‌ می‌شود. متن به‌دست آمده  از اعمال دستی این تغییرات به عنوان خروجی اصلاح‌گر املایی گوگل درنظر گرفته شد. چون فرایند استفاده از این اصلاح‌گر زمان‌بر است تنها برای ارزیابی دادگان‌هایی با حجم کوچک استفاده می‌شود.\n",
        "\n",
        "- **ویراست‌من** برای ارزیابی تنها به کمک افزونه‌ای در MS Office Word در دسترس است و با اعمال دستی می‌توان کلمات را تصحیح کرد. به دلیل این محدودیت ارزیابی فقط روی مجموعه‌داده‌های کوچک امکان‌پذیر است. ویراست‌من ممکن است برای هر کلمه‌ای که اشتباه تشخیص دهد چندین پیشنهاد ارائه دهد که در این ارزیابی اولین گزینه انتخاب می‌شود بدون توجه به این که کدام‌یک از پیشنهاد‌‌ها می‌تواند پیشنهاد مناسب‌تری باشد.\n",
        "\n",
        "- **پاک‌نویس**: برای ارزیابی از API پاک‌نویس که مبتنی بر توکن است استفاده کردیم که توکن توسط تیم پاک‌نویس در اختیار شرکت دادماتک قرارگرفته است.\n",
        "\n",
        "\n",
        "- **نویسه** دمو اصلاح‌گر نویسه نسخه‌ی ۱ و ۲ در [این آدرس](https://dadmatech.ir/#/products/SpellChecker) و در دو تب جدا قرار دارد.\n",
        "\n",
        "\n",
        "\n",
        "## ملاحظات ارزیابی\n",
        "\n",
        "\n",
        "- یکی از چالش‌های ارزیابی اصلاح‌گر املایی برای متن فارسی، نوشته‌شدن واژه‌ها به اشکال مختلف است که این تنوع در استفاده یا عدم استفاده از نیم‌فاصله و فاصله یا استفاده از برخی کاراکتر‌های خاص مثل همزه و تنوین پیش‌می‌آید. اما چون اشکالاتی حتی در دیتای صحیح دیده می‌شود و تشخیص درستی آن گاهی تنها به کمک زبان‌شناس ممکن است، تا حد امکان خطاهای مربوط به این تفاوت برای سامانه‌ها درنظر گرفته نمی‌شود. \n",
        "\n",
        "- برخی از اصلاح‌گرهای املایی مانند ویراست‌من، اغلب به ازای هر واژه چندین واژه کاندیدا پیشنهاد می‌دهند. در این ارزیابی، تنها نخستین پیشنهاد هر سامانه، به عنوان واژه گزارش شده توسط سامانه برای هر واژه لحاظ شده و سایر پیشنهادها حتی در صورت صحت، نادیده گرفته شده‌اند.\n",
        "\n",
        "\n",
        "\n",
        "## جدول و نتایج   \n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "### دادگان ذره‌بین\n",
        "\n",
        "| الگوریتم | نرخ کشف کلمات نادرست | نرخ تصحیح کلمات خطا | نرخ تخریب کلمات صحیح  | نرخ صحت کشف خطاها  |\n",
        "| -- | -- | -- | -- | -- |\n",
        "| گوگل | **۰.۹۳۱۸** | **۰.۹۱۴** | ۰.۰۰۲۶ | ۰.۹۹۶۲ |\n",
        "| نویسه۲ | ۰.۸۹۵۵ | ۰.۸۱۳۱ | ۰.۰۰۱۶ | ۰.۹۹۷۶ |\n",
        "| پاک‌نویس | ۰.۸۷۷ | ۰.۷۸۸۹ | ۰.۰۳۱۷ | ۰.۹۵۵۸ |\n",
        "| ویراست‌من | ۰.۸۳۴۲ | ۰.۸۰۲۸ | **۰.۰۰۰۶** | **۰.۹۹۹۱** |\n",
        "\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "### دادگان PerSpellData \n",
        "\n",
        "| الگوریتم | نرخ کشف کلمات نادرست | نرخ تصحیح کلمات خطا | نرخ تخریب کلمات صحیح  | نرخ صحت کشف خطاها  |\n",
        "| -- | -- | -- | -- | -- |\n",
        "| پاک‌نویس | **۰.۹۴۵۵** | ۰.۸۲۴۵ | ۰.۰۱۶ | ۰.۸۳۹۶ |\n",
        "| نویسه۲ | ۰.۹۱۹۶ | **۰.۸۳۵۸** | ۰.۰۰۳۴ | ۰.۹۵۹۴ |\n",
        "| ویراست‌من | ۰.۷۹۵۲ | ۰.۶۵۰۸ | **۰.۰۰۰۸** | **۰.۹۸۹۲** |\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "### دادگان شرق\n",
        "\n",
        "| الگوریتم | نرخ کشف کلمات نادرست | نرخ تصحیح کلمات خطا | نرخ تخریب کلمات صحیح  | نرخ صحت کشف خطاها  |\n",
        "| -- | -- | -- | -- | -- |\n",
        "| نویسه۲ | **۰.۸۲۴۳** | **۰.۶۴۸۶** | ۰.۰۰۳۸ | ۰.۹۶۸۳ |\n",
        "| پاک‌نویس | ۰.۷۵۶۸ | ۰.۵۸۱۱ | ۰.۰۲۹۵ | ۰.۷۸۵ |\n",
        "| ویراست‌من | ۰.۶۰۳۶ | ۰.۴۸۲ | **۰.۰** | **۱.۰** |\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "### دادگان نویسه - متن خبر\n",
        "\n",
        "| الگوریتم | نرخ کشف کلمات نادرست | نرخ تصحیح کلمات خطا | نرخ تخریب کلمات صحیح  | نرخ صحت کشف خطاها  |\n",
        "| -- | -- | -- | -- | -- |\n",
        "| نویسه۲ | **۰.۸۳۸۶** | **۰.۷۳۶۷** | **۰.۰۰۳۷** | **۰.۹۸۳۲** |\n",
        "| پاک‌نویس | ۰.۷۹۳۱ | ۰.۶۶۰۷ | ۰.۰۲۱۷ | ۰.۹۰۶۳ |\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "### دادگان نویسه - عنوان خبر - ۵۳۹ جمله\n",
        "\n",
        "| الگوریتم | نرخ کشف کلمات نادرست | نرخ تصحیح کلمات خطا | نرخ تخریب کلمات صحیح  | نرخ صحت کشف خطاها  |\n",
        "| -- | -- | -- | -- | -- |\n",
        "| نویسه۲ | **۰.۸۳۱۴** | **۰.۷۲۱۶** | **۰.۰۰۳** | **۰.۹۶۸** |\n",
        "| پاک‌نویس | ۰.۷۸۴۳ | ۰.۶۷۰۶ | ۰.۲۲۸ | ۰.۷۹۲۱ |\n",
        "| گوگل | ۰.۷۳۹۲ | ۰.۷۰۲ | ۰.۰۰۴۵ | ۰.۹۴۴۹ |\n",
        "| ویراست‌من | ۰.۶ | ۰.۵ | ۰.۰۰۳۲ | ۰.۹۵۳۳ |\n",
        "\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "### دادگان نویسه - عنوان خبر\n",
        "\n",
        "| الگوریتم | نرخ کشف کلمات نادرست | نرخ تصحیح کلمات خطا | نرخ تخریب کلمات صحیح  | نرخ صحت کشف خطاها  |\n",
        "| -- | -- | -- | -- | -- |\n",
        "| نویسه۲ | **۰.۸۲۸** | **۰.۷۱۰۲** | **۰.۰۰۸۶** | **۰.۹۰۸۳** |\n",
        "| پاک‌نویس | ۰.۷۸۰۲ | ۰.۶۴۵۸ | ۰.۰۲۳۵ | ۰.۷۷۷ |\n",
        "\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "0LBFyy7qd4ZF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSOKupJG-DZr"
      },
      "source": [
        "# کد"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7X3uitE-HLc"
      },
      "source": [
        "## آماده‌سازی"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[دانلود دادگان](https://drive.google.com/drive/folders/1JhU8JQI5bLiLbWdvDJqvDTJpRm_D-Xa0?usp=sharing)"
      ],
      "metadata": {
        "id": "HX1Fk_09wIW5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkS7Vab8UP3t",
        "outputId": "c131d03e-5841-4000-84ee-aa49e2100620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Dadmatech/spell_checker/comparison\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/MyDrive/Dadmatech/spell_checker/comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "keZ33ZFxUfzz"
      },
      "outputs": [],
      "source": [
        "with open('./data/chars.txt') as f:\n",
        "  chars = f.readlines()\n",
        "char_dict = {c.split(', ')[0]:c.split(', ')[1][0] for c in chars}\n",
        "\n",
        "def char_refinement(text):\n",
        "  s = ''\n",
        "  for i in text:\n",
        "    if i in normal_chars:\n",
        "      s += normal_chars[i]\n",
        "    elif i in ['\\u200c', '_', ' ']:\n",
        "      s += i\n",
        "    elif not i in special_chars:\n",
        "      s += i\n",
        "  return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ogg-Nzi0_eMH"
      },
      "outputs": [],
      "source": [
        "normal_chars = {}\n",
        "for i in char_dict:\n",
        "  if char_dict[i] != '\\n':\n",
        "    normal_chars[i] = char_dict[i]\n",
        "# normal_chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RQmLYn_fJ5kG"
      },
      "outputs": [],
      "source": [
        "special_chars = []\n",
        "for i in char_dict:\n",
        "  if char_dict[i] == '\\n':\n",
        "    special_chars.append(i)\n",
        "# special_chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MBpQ-DYqMtu"
      },
      "source": [
        "## خواندن فایل‌ها"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YuBVPc_SnCoX"
      },
      "outputs": [],
      "source": [
        "def read_dataset (dataset_name, dataset_type):\n",
        "  with open(f'data/{dataset_name}/{dataset_name}_{dataset_type}.txt') as f:\n",
        "    data = f.readlines()\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbw0_zQgnD-W",
        "outputId": "5e023e6f-8ea9-4dc6-e71d-4fbb91b1ae45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lengths: 1033, 1033, 1033, 1033\n"
          ]
        }
      ],
      "source": [
        "# zarebin\n",
        "\n",
        "zarebin_wrongs = read_dataset('zarebin', 'wrongs')\n",
        "zarebin_corrects = read_dataset('zarebin', 'corrects')\n",
        "zarebin_google = read_dataset('zarebin', 'google')\n",
        "zarebin_virastman = read_dataset('zarebin', 'virastman')\n",
        "zarebin_paknevis = read_dataset('zarebin', 'paknevis')\n",
        "zarebin_nevise = read_dataset('zarebin', 'nevise')\n",
        "\n",
        "print(f'lengths: {len(zarebin_virastman)}, {len(zarebin_paknevis)}, {len(zarebin_nevise)}, {len(zarebin_google)}' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96dl7RlsnzeD",
        "outputId": "7c3f3b8f-c705-4b45-fae2-311885102f78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lengths: 1127, 1127, 1127\n"
          ]
        }
      ],
      "source": [
        "# PerSpellData\n",
        "\n",
        "PerSpellData_wrongs = read_dataset('PerSpellData', 'wrongs')\n",
        "PerSpellData_corrects = read_dataset('PerSpellData', 'corrects')\n",
        "PerSpellData_virastman = read_dataset('PerSpellData', 'virastman')\n",
        "PerSpellData_paknevis = read_dataset('PerSpellData', 'paknevis')\n",
        "PerSpellData_nevise = read_dataset('PerSpellData', 'nevise')\n",
        "\n",
        "print(f'lengths: {len(PerSpellData_virastman)}, {len(PerSpellData_paknevis)}, {len(PerSpellData_nevise)}' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRGNlTXCoqzg",
        "outputId": "9ee161bb-c4bf-450d-98b2-c5856ac77207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lengths: 223, 223, 223, 223, 223\n"
          ]
        }
      ],
      "source": [
        "# shargh\n",
        "\n",
        "shargh_wrongs = read_dataset('shargh', 'wrongs')\n",
        "shargh_corrects = read_dataset('shargh', 'corrects')\n",
        "shargh_virastman = read_dataset('shargh', 'virastman')\n",
        "shargh_paknevis = read_dataset('shargh', 'paknevis')\n",
        "shargh_nevise = read_dataset('shargh', 'nevise')\n",
        "\n",
        "print(f'lengths: {len(shargh_corrects)}, {len(shargh_wrongs)}, {len(shargh_virastman)}, {len(shargh_paknevis)}, {len(shargh_nevise)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkQDhcAOoWeM",
        "outputId": "c4157b0b-eb86-486a-c2dc-c4f94f40e5b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lengths: 451, 451\n"
          ]
        }
      ],
      "source": [
        "# nevise news 451\n",
        "\n",
        "nevise_wrongs = read_dataset('nevise-news-451', 'wrongs')\n",
        "nevise_corrects = read_dataset('nevise-news-451', 'corrects')\n",
        "nevise_paknevis = read_dataset('nevise-news-451', 'paknevis')\n",
        "nevise_nevise = read_dataset('nevise-news-451', 'nevise')\n",
        "\n",
        "print(f'lengths: {len(nevise_paknevis)}, {len(nevise_nevise)}' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e78Hxvnrovba",
        "outputId": "e955db72-85f2-4a04-d715-0fb0b169b3f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lengths: 539, 539, 539\n"
          ]
        }
      ],
      "source": [
        "# nevise news title 539\n",
        "\n",
        "nevise_titles_wrongs = read_dataset('nevise-news-title-539', 'wrongs')\n",
        "nevise_titles_corrects = read_dataset('nevise-news-title-539', 'corrects')\n",
        "nevise_titles_google = read_dataset('nevise-news-title-539', 'google')\n",
        "nevise_titles_virastman = read_dataset('nevise-news-title-539', 'virastman')\n",
        "nevise_titles_paknevis = read_dataset('nevise-news-title-539', 'paknevis')\n",
        "nevise_titles_nevise = read_dataset('nevise-news-title-539', 'nevise')\n",
        "nevise_titles_nevise_v1 = read_dataset('nevise-news-title-539', 'nevise-v1')\n",
        "\n",
        "print(f'lengths: {len(nevise_titles_google)}, {len(nevise_titles_paknevis)}, {len(nevise_titles_nevise)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpLD7Lk5oyel",
        "outputId": "a5f918dc-86c8-485d-e609-599ba0c27bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lengths: 19421, 19421, 19421\n"
          ]
        }
      ],
      "source": [
        "# nevise news title all\n",
        "\n",
        "nevise_titles_all_wrongs = read_dataset('nevise-news-title-all', 'wrongs')\n",
        "nevise_titles_all_corrects = read_dataset('nevise-news-title-all', 'corrects')\n",
        "nevise_titles_all_paknevis = read_dataset('nevise-news-title-all', 'paknevis')\n",
        "nevise_titles_all_nevise = read_dataset('nevise-news-title-all', 'nevise')\n",
        "\n",
        "print(f'lengths: {len(nevise_titles_all_paknevis)}, {len(nevise_titles_all_nevise)}, {len(nevise_titles_all_corrects)}' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfdlxc_kTRSL"
      },
      "source": [
        "## توابع ارزیابی"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dxYtOm53TTYS"
      },
      "outputs": [],
      "source": [
        "from nltk import edit_distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pxrNO_aGTTYT"
      },
      "outputs": [],
      "source": [
        "def get_tok_info(index, w_tok, c_tokens, p_tokens, p_tokens_without_special, p_tokens_subwords, p_tokens_bi, verbose=False):\n",
        "  string_file = ''\n",
        "  output_info = {\n",
        "      'wrong': False,\n",
        "      'not_detected': False,\n",
        "      'detected': False,\n",
        "      'c2w': False,\n",
        "      'w2c': False,\n",
        "      'c2c': False,\n",
        "  }\n",
        "  if verbose:\n",
        "    print('\\n', w_tok)\n",
        "  is_correct = pseudo_is_contain(query=c_tokens, key=w_tok, key_index=index)\n",
        "  is_changed = not pseudo_is_contain(\n",
        "      query=p_tokens, key=w_tok, key_index=index\n",
        "      ) and not pseudo_is_contain(\n",
        "          query=p_tokens_without_special, key=w_tok, key_index=index\n",
        "      ) and not pseudo_is_contain(\n",
        "          query=p_tokens_subwords, key=w_tok, key_index=index\n",
        "      ) and not pseudo_is_contain(\n",
        "          query=p_tokens_bi, key=w_tok, key_index=index\n",
        "      ) \n",
        "\n",
        "  if not is_correct:\n",
        "    output_info['wrong'] = True\n",
        "    if verbose:\n",
        "      print('wrong', w_tok)\n",
        "    # string_file +=  f'wrong {w_tok}\\n'\n",
        "\n",
        "  if not is_correct and not is_changed:\n",
        "    output_info['not_detected'] = True\n",
        "    # string_file += f'not_detected {w_tok}\\n'\n",
        "    if verbose:\n",
        "      print('not_detected', w_tok)\n",
        "\n",
        "  if is_correct and is_changed:\n",
        "    output_info['c2w'] = True\n",
        "    if verbose:\n",
        "      print('c2w', w_tok)\n",
        "    string_file += f'c2w {w_tok}\\n'\n",
        "\n",
        "  if is_correct and not is_changed:\n",
        "    output_info['c2c'] = True\n",
        "    if verbose:\n",
        "      print('c2c', w_tok)\n",
        "    # string_file += f'c2c {w_tok}\\n'\n",
        "\n",
        "  if (not is_correct) and is_changed:\n",
        "    output_info['detected'] = True\n",
        "    if verbose:\n",
        "      print('detected', w_tok)\n",
        "    #w_detected += 1\n",
        "    # string_file += f'detected {w_tok}\\n'\n",
        "\n",
        "    c_paired_tok = get_paired_token(query=c_tokens, key=w_tok, key_index=index)\n",
        "    p_paired_tok = get_paired_token(query=p_tokens, key=w_tok, key_index=index)\n",
        "    p_paired_tok_without_special = get_paired_token(query=p_tokens_without_special, key=w_tok, key_index=index)\n",
        "    p_paired_tok_subwords = get_paired_token(query=p_tokens_subwords, key=w_tok, key_index=index)\n",
        "    p_paired_tok_bi = get_paired_token(query=p_tokens_bi, key=w_tok, key_index=index)\n",
        "    if verbose:\n",
        "      print(c_paired_tok, p_paired_tok, p_paired_tok_without_special, p_paired_tok_subwords)\n",
        "    if is_soft_equal(\n",
        "        c_paired_tok, p_paired_tok\n",
        "        ) or is_soft_equal(\n",
        "            c_paired_tok, p_paired_tok_without_special\n",
        "        ) or is_soft_equal(\n",
        "            c_paired_tok, p_paired_tok_subwords\n",
        "        ) or is_soft_equal(\n",
        "            c_paired_tok, p_paired_tok_bi\n",
        "        ):    \n",
        "      output_info['w2c'] = True\n",
        "      if verbose:\n",
        "        print('w2c', w_tok)\n",
        "      # string_file += f'w2c {w_tok}\\n'\n",
        "      \n",
        "  return output_info, string_file\n",
        "\n",
        "\n",
        "def get_paired_token(query, key, key_index, r=4):\n",
        "  most_similar = ''\n",
        "  most_similar_score = len(query)\n",
        "  for query_token in query[max(0, key_index - r): min(len(query), key_index + r)]:\n",
        "    distance = edit_distance(query_token, key)\n",
        "    if most_similar_score > distance:\n",
        "      most_similar = query_token\n",
        "      most_similar_score = distance\n",
        "  return most_similar\n",
        "\n",
        "def is_soft_equal(c_token, p_token):\n",
        "  return c_token == p_token or c_token == remove_special_chars(p_token)\n",
        "\n",
        "\n",
        "def remove_special_chars(text):\n",
        "  for special_ch in special_chars:\n",
        "    text = text.replace(special_ch, '')\n",
        "  return text\n",
        "\n",
        "def replace_halfspaces(text, replace_with=' '):\n",
        "  text = text.replace('\\\\u200c', replace_with)\n",
        "  return text.replace('\\u200c', replace_with)\n",
        "\n",
        "\n",
        "def pseudo_is_contain(query, key, key_index, r=4):\n",
        "  return key in query[max(0, key_index - r): min(len(query), key_index + r)]\n",
        "\n",
        "\n",
        "def words_halfspaces (list_of_words):\n",
        "  list_of_words = [word.split('‌') for word in list_of_words]\n",
        "  return [sub for words in list_of_words for sub in words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fjjQYd5kTTYW"
      },
      "outputs": [],
      "source": [
        "def update_eval_params(eval_params, info):\n",
        "  for i in info:\n",
        "    eval_params[i] += info[i]\n",
        "  return eval_params\n",
        "\n",
        "def best_info (info1, info2):\n",
        "  if info2['c2c'] or info2['w2c']:\n",
        "    return info2, 2\n",
        "  return info1, 1\n",
        "\n",
        "def eval(wrong_sentence, correct_sentence, predicted_sentence, verbose=False):\n",
        "    eval_params = {\n",
        "          'wrong': 0,\n",
        "          'not_detected': 0,\n",
        "          'detected': 0,\n",
        "          'c2w': 0,\n",
        "          'w2c': 0,\n",
        "          'c2c': 0,    \n",
        "    }\n",
        "    string_file_all = ''\n",
        "\n",
        "    w_tokens = char_refinement(wrong_sentence).split()\n",
        "    c_tokens = char_refinement(correct_sentence).split()\n",
        "    p_tokens = char_refinement(predicted_sentence).split()\n",
        "\n",
        "    w_tokens = [str(int(tok)) if tok.isdigit() else tok for tok in w_tokens]\n",
        "    c_tokens = [str(int(tok)) if tok.isdigit() else tok for tok in c_tokens]\n",
        "    p_tokens = [str(int(tok)) if tok.isdigit() else tok for tok in p_tokens]\n",
        "    \n",
        "    w_tokens_bi = [f'{w1}{w2}' for w1, w2 in zip(w_tokens, w_tokens[1:])]\n",
        "    c_tokens_bi = [f'{c1}{c2}' for c1, c2 in zip(c_tokens, c_tokens[1:])]\n",
        "\n",
        "    p_tokens = [p.replace('\\\\u200c', '\\u200c') for p in p_tokens]\n",
        "    p_tokens_special_removed = [remove_special_chars(p) for p in p_tokens]\n",
        "    p_tokens_subwords = words_halfspaces(p_tokens)\n",
        "    p_tokens_bi = [f'{p1}{p2}' for p1, p2 in zip(p_tokens, p_tokens[1:])]\n",
        "    c_tokens = [remove_special_chars(c) for c in c_tokens]\n",
        "    w_tokens = [remove_special_chars(w) for w in w_tokens]\n",
        "    if verbose:\n",
        "      print('in', w_tokens)\n",
        "      print('correct', c_tokens)\n",
        "      print('origin', p_tokens)\n",
        "      print('removed', p_tokens_special_removed)\n",
        "      print('sub', p_tokens_subwords)\n",
        "      print('bi', p_tokens_bi)\n",
        "    double_continue_flag = False\n",
        "    for index, w_t in enumerate(w_tokens):\n",
        "      if double_continue_flag:\n",
        "        double_continue_flag = False\n",
        "        continue\n",
        "      which = 1\n",
        "      info, string_file = get_tok_info(index, w_t, c_tokens, p_tokens, p_tokens_special_removed, p_tokens_subwords, p_tokens_bi)\n",
        "\n",
        "      if index < len(w_tokens)-1:\n",
        "        w_tok = w_tokens_bi[index]\n",
        "\n",
        "        info_bi, string_file_bi = get_tok_info(index, w_tok, c_tokens_bi, p_tokens, p_tokens_special_removed, p_tokens_subwords, len(p_tokens_bi)*[' '])\n",
        "        \n",
        "        info, which = best_info(info, info_bi)\n",
        "        if which == 2:\n",
        "          if string_file_bi != '' :\n",
        "            string_file_all += '** bi\\n **' + string_file_bi\n",
        "          double_continue_flag = True\n",
        "\n",
        "\n",
        "      eval_params = update_eval_params(eval_params, info)\n",
        "      if which == 1 :\n",
        "        if string_file != '' :\n",
        "          string_file_all += '** normal\\n **' + string_file\n",
        "    # string_file_all += f'{eval_params}'\n",
        "    # print(eval_params)\n",
        "    return eval_params, string_file_all\n",
        "\n",
        "def write_log(string_to_file, names):\n",
        "  with open(f'../logs/{names[0]}_{names[1]}_log.txt', 'w') as f:\n",
        "    f.write(string_to_file)\n",
        "\n",
        "\n",
        "def eval_spell_checker (wrongs, corrects, predicts, names):\n",
        "  eval_params = {\n",
        "          'wrong': 0,\n",
        "          'not_detected': 0,\n",
        "          'detected': 0,\n",
        "          'c2w': 0,\n",
        "          'w2c': 0,\n",
        "          'c2c': 0,    \n",
        "  }\n",
        "  string_file = ''\n",
        "  for index, (wrong_sentence, correct_sentence, predicted_sentence) in enumerate(zip(wrongs, corrects, predicts)):\n",
        "    sentence_eval_params, string_file_sentence = eval(wrong_sentence, correct_sentence, predicted_sentence)\n",
        "    if string_file_sentence != '':\n",
        "      string_file += f'\\n{index}\\n'\n",
        "      string_file += wrong_sentence +'\\n'\n",
        "      string_file += correct_sentence +'\\n'\n",
        "      string_file += predicted_sentence + '\\n'\n",
        "    \n",
        "    eval_params = update_eval_params(eval_params, sentence_eval_params)\n",
        "    string_file += string_file_sentence\n",
        "  # print(eval_params)\n",
        "  write_log(string_file, names)\n",
        "  print()\n",
        "  w2w = eval_params['detected'] - eval_params['w2c']\n",
        "  wd_rate = round(eval_params['detected']/eval_params['wrong'], 4)\n",
        "  w2c_rate = round(eval_params['w2c']/eval_params['wrong'], 4)\n",
        "  c2w_rate = round(eval_params['c2w']/(eval_params['c2w'] + eval_params['c2c']), 4)\n",
        "  precision = round((eval_params['w2c'] + w2w)/(eval_params['c2w'] + eval_params['w2c'] + w2w) , 4)\n",
        "  print(f'{names[1]} on {names[0]}')\n",
        "  print(f'wrong detection rate:{wd_rate} \\twrong correction rate:{w2c_rate} \\tcorrect to wrong rate:{c2w_rate} \\tprecision:{precision}')\n",
        "  print(eval_params)\n",
        "  return eval_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvV4dGb8GD19",
        "outputId": "4df3b145-f0aa-438a-9651-1f170d5a35f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nevise2 on Nevise news titles\n",
            "wrong detection rate:1.0 \twrong correction rate:0.7778 \tcorrect to wrong rate:0.0125 \tprecision:0.9\n",
            "{'wrong': 9, 'not_detected': 0, 'detected': 9, 'c2w': 1, 'w2c': 7, 'c2c': 79}\n"
          ]
        }
      ],
      "source": [
        "# tiny test \n",
        "\n",
        "eval_nevise_titles_nevise = eval_spell_checker (nevise_titles_wrongs[:10], nevise_titles_corrects[:10], nevise_titles_nevise[:10], ['Nevise news titles', 'Nevise2'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kifmkDDamWvT"
      },
      "source": [
        "## اجرای ارزیابی"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "717e8172-7a62-49c6-abd6-8b3d7b0c3283",
        "id": "aXcAjL90mWvV"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Google on Zarebin\n",
            "wrong detection rate:0.9318 \twrong correction rate:0.914 \tcorrect to wrong rate:0.0026 \tprecision:0.9962\n",
            "{'wrong': 1407, 'not_detected': 96, 'detected': 1311, 'c2w': 5, 'w2c': 1286, 'c2c': 1887}\n",
            "\n",
            "Virastman on Zarebin\n",
            "wrong detection rate:0.8342 \twrong correction rate:0.8028 \tcorrect to wrong rate:0.0006 \tprecision:0.9991\n",
            "{'wrong': 1405, 'not_detected': 233, 'detected': 1172, 'c2w': 1, 'w2c': 1128, 'c2c': 1780}\n",
            "\n",
            "Paknevis on Zarebin\n",
            "wrong detection rate:0.877 \twrong correction rate:0.7889 \tcorrect to wrong rate:0.0317 \tprecision:0.9558\n",
            "{'wrong': 1407, 'not_detected': 173, 'detected': 1234, 'c2w': 57, 'w2c': 1110, 'c2c': 1739}\n",
            "\n",
            "Nevise2 on Zarebin\n",
            "wrong detection rate:0.8955 \twrong correction rate:0.8131 \tcorrect to wrong rate:0.0016 \tprecision:0.9976\n",
            "{'wrong': 1407, 'not_detected': 147, 'detected': 1260, 'c2w': 3, 'w2c': 1144, 'c2c': 1833}\n"
          ]
        }
      ],
      "source": [
        "# Result on Zarebin\n",
        "eval_zarebin_google = eval_spell_checker (zarebin_wrongs, zarebin_corrects, zarebin_google, ['Zarebin', 'Google'])\n",
        "eval_zarebin_virastman = eval_spell_checker (zarebin_wrongs, zarebin_corrects, zarebin_virastman, ['Zarebin', 'Virastman'])\n",
        "eval_zarebin_paknevis = eval_spell_checker (zarebin_wrongs, zarebin_corrects, zarebin_paknevis, ['Zarebin', 'Paknevis'])\n",
        "eval_zarebin_nevise = eval_spell_checker (zarebin_wrongs, zarebin_corrects, zarebin_nevise, ['Zarebin', 'Nevise2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f733ac6-8130-4bcf-c42c-d5e23adf1292",
        "id": "62PiRKsXmWva"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Virastman on PerSpellData\n",
            "wrong detection rate:0.7952 \twrong correction rate:0.6508 \tcorrect to wrong rate:0.0008 \tprecision:0.9892\n",
            "{'wrong': 1157, 'not_detected': 237, 'detected': 920, 'c2w': 10, 'w2c': 753, 'c2c': 13252}\n",
            "\n",
            "Paknevis on PerSpellData\n",
            "wrong detection rate:0.9455 \twrong correction rate:0.8245 \tcorrect to wrong rate:0.016 \tprecision:0.8396\n",
            "{'wrong': 1157, 'not_detected': 63, 'detected': 1094, 'c2w': 209, 'w2c': 954, 'c2c': 12848}\n",
            "\n",
            "Nevise2 on PerSpellData\n",
            "wrong detection rate:0.9196 \twrong correction rate:0.8358 \tcorrect to wrong rate:0.0034 \tprecision:0.9594\n",
            "{'wrong': 1157, 'not_detected': 93, 'detected': 1064, 'c2w': 45, 'w2c': 967, 'c2c': 13321}\n"
          ]
        }
      ],
      "source": [
        "# Result on PerSpellData\n",
        "\n",
        "eval_perspell_virastman = eval_spell_checker (PerSpellData_wrongs, PerSpellData_corrects, PerSpellData_virastman, ['PerSpellData', 'Virastman'])\n",
        "eval_perspell_paknevis = eval_spell_checker (PerSpellData_wrongs, PerSpellData_corrects, PerSpellData_paknevis, ['PerSpellData', 'Paknevis'])\n",
        "eval_perspell_nevise = eval_spell_checker (PerSpellData_wrongs, PerSpellData_corrects, PerSpellData_nevise, ['PerSpellData', 'Nevise2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58aee81b-a1a8-49e1-967e-00c808482c64",
        "id": "2lABT0tAmWv6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Virastman on Shargh\n",
            "wrong detection rate:0.6036 \twrong correction rate:0.482 \tcorrect to wrong rate:0.0 \tprecision:1.0\n",
            "{'wrong': 222, 'not_detected': 88, 'detected': 134, 'c2w': 0, 'w2c': 107, 'c2c': 1575}\n",
            "\n",
            "Paknevis on Shargh\n",
            "wrong detection rate:0.7568 \twrong correction rate:0.5811 \tcorrect to wrong rate:0.0295 \tprecision:0.785\n",
            "{'wrong': 222, 'not_detected': 54, 'detected': 168, 'c2w': 46, 'w2c': 129, 'c2c': 1515}\n",
            "\n",
            "Nevise2 on Shargh\n",
            "wrong detection rate:0.8243 \twrong correction rate:0.6486 \tcorrect to wrong rate:0.0038 \tprecision:0.9683\n",
            "{'wrong': 222, 'not_detected': 39, 'detected': 183, 'c2w': 6, 'w2c': 144, 'c2c': 1579}\n"
          ]
        }
      ],
      "source": [
        "# Result on Shargh\n",
        "\n",
        "eval_shargh_virastman = eval_spell_checker (shargh_wrongs, shargh_corrects, shargh_virastman, ['Shargh', 'Virastman'])\n",
        "eval_shargh_paknevis = eval_spell_checker (shargh_wrongs, shargh_corrects, shargh_paknevis, ['Shargh', 'Paknevis'])\n",
        "eval_shargh_nevise = eval_spell_checker (shargh_wrongs, shargh_corrects, shargh_nevise, ['Shargh', 'Nevise2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fbff0c7-88c6-4a52-8341-9c34884acdb6",
        "id": "MkZK32fFmWv9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Paknevis on Nevise\n",
            "wrong detection rate:0.7931 \twrong correction rate:0.6607 \tcorrect to wrong rate:0.0217 \tprecision:0.9063\n",
            "{'wrong': 2305, 'not_detected': 477, 'detected': 1828, 'c2w': 189, 'w2c': 1523, 'c2c': 8509}\n",
            "\n",
            "Nevise2 on Nevise\n",
            "wrong detection rate:0.8386 \twrong correction rate:0.7367 \tcorrect to wrong rate:0.0037 \tprecision:0.9832\n",
            "{'wrong': 2305, 'not_detected': 372, 'detected': 1933, 'c2w': 33, 'w2c': 1698, 'c2c': 8827}\n"
          ]
        }
      ],
      "source": [
        "# Result on Nevise \n",
        "\n",
        "eval_nevise_paknevis = eval_spell_checker (nevise_wrongs, nevise_corrects, nevise_paknevis, ['Nevise', 'Paknevis'])\n",
        "eval_nevise_nevise = eval_spell_checker (nevise_wrongs, nevise_corrects, nevise_nevise, ['Nevise', 'Nevise2'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Result on nevisee news title 539\n",
        "\n",
        "eval_nevise_titles_google = eval_spell_checker (nevise_titles_wrongs, nevise_titles_corrects, nevise_titles_google, ['Nevise-news-titles-539', 'Google'])\n",
        "eval_nevise_titles_virastman = eval_spell_checker (nevise_titles_wrongs, nevise_titles_corrects, nevise_titles_virastman, ['Nevise-news-titles-539', 'Virastman'])\n",
        "eval_nevise_titles_paknevis = eval_spell_checker (nevise_titles_wrongs, nevise_titles_corrects, nevise_titles_paknevis, ['Nevise-news-titles-539', 'Paknevis'])\n",
        "eval_nevise_titles_nevise = eval_spell_checker (nevise_titles_wrongs, nevise_titles_corrects, nevise_titles_nevise, ['Nevise-news-titles-539', 'Nevise2'])\n",
        "eval_nevise_titles_nevise_v1 = eval_spell_checker (nevise_titles_wrongs, nevise_titles_corrects, nevise_titles_nevise_v1, ['nevise-news-title-539', 'nevise-v1'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0cf9r78J7_N",
        "outputId": "5358cbbe-be1d-4e1c-c998-151a9f24a743"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Google on Nevise-news-titles-539\n",
            "wrong detection rate:0.7392 \twrong correction rate:0.702 \tcorrect to wrong rate:0.0045 \tprecision:0.9449\n",
            "{'wrong': 510, 'not_detected': 133, 'detected': 377, 'c2w': 22, 'w2c': 358, 'c2c': 4848}\n",
            "\n",
            "Virastman on Nevise-news-titles-539\n",
            "wrong detection rate:0.6 \twrong correction rate:0.5 \tcorrect to wrong rate:0.0032 \tprecision:0.9533\n",
            "{'wrong': 510, 'not_detected': 204, 'detected': 306, 'c2w': 15, 'w2c': 255, 'c2c': 4635}\n",
            "\n",
            "Paknevis on Nevise-news-titles-539\n",
            "wrong detection rate:0.7843 \twrong correction rate:0.6706 \tcorrect to wrong rate:0.0228 \tprecision:0.7921\n",
            "{'wrong': 510, 'not_detected': 110, 'detected': 400, 'c2w': 105, 'w2c': 342, 'c2c': 4497}\n",
            "\n",
            "Nevise2 on Nevise-news-titles-539\n",
            "wrong detection rate:0.8314 \twrong correction rate:0.7216 \tcorrect to wrong rate:0.003 \tprecision:0.968\n",
            "{'wrong': 510, 'not_detected': 86, 'detected': 424, 'c2w': 14, 'w2c': 368, 'c2c': 4691}\n",
            "\n",
            "nevise-v1 on nevise-news-title-539\n",
            "wrong detection rate:0.7647 \twrong correction rate:0.6824 \tcorrect to wrong rate:0.0019 \tprecision:0.9774\n",
            "{'wrong': 510, 'not_detected': 120, 'detected': 390, 'c2w': 9, 'w2c': 348, 'c2c': 4707}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cb0485e-374a-40be-90b2-4a7ded896337",
        "id": "3xxe2GmkmWv_"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Google on Nevise-news-titles-539\n",
            "wrong detection rate:0.7392 \twrong correction rate:0.702 \tcorrect to wrong rate:0.0045 \tprecision:0.9449\n",
            "{'wrong': 510, 'not_detected': 133, 'detected': 377, 'c2w': 22, 'w2c': 358, 'c2c': 4848}\n",
            "\n",
            "Virastman on Nevise-news-titles-539\n",
            "wrong detection rate:0.6 \twrong correction rate:0.5 \tcorrect to wrong rate:0.0032 \tprecision:0.9533\n",
            "{'wrong': 510, 'not_detected': 204, 'detected': 306, 'c2w': 15, 'w2c': 255, 'c2c': 4635}\n",
            "\n",
            "Paknevis on Nevise-news-titles-539\n",
            "wrong detection rate:0.7843 \twrong correction rate:0.6706 \tcorrect to wrong rate:0.0228 \tprecision:0.7921\n",
            "{'wrong': 510, 'not_detected': 110, 'detected': 400, 'c2w': 105, 'w2c': 342, 'c2c': 4497}\n",
            "\n",
            "Nevise2 on Nevise-news-titles-539\n",
            "wrong detection rate:0.8314 \twrong correction rate:0.7216 \tcorrect to wrong rate:0.003 \tprecision:0.968\n",
            "{'wrong': 510, 'not_detected': 86, 'detected': 424, 'c2w': 14, 'w2c': 368, 'c2c': 4691}\n",
            "\n",
            "nevise-v1 on nevise-news-title-539\n",
            "wrong detection rate:0.7647 \twrong correction rate:0.6824 \tcorrect to wrong rate:0.0019 \tprecision:0.9774\n",
            "{'wrong': 510, 'not_detected': 120, 'detected': 390, 'c2w': 9, 'w2c': 348, 'c2c': 4707}\n"
          ]
        }
      ],
      "source": [
        "# Result on nevisee news title 539\n",
        "\n",
        "eval_nevise_titles_google = eval_spell_checker (nevise_titles_wrongs, nevise_titles_corrects, nevise_titles_google, ['Nevise-news-titles-539', 'Google'])\n",
        "eval_nevise_titles_virastman = eval_spell_checker (nevise_titles_wrongs, nevise_titles_corrects, nevise_titles_virastman, ['Nevise-news-titles-539', 'Virastman'])\n",
        "eval_nevise_titles_paknevis = eval_spell_checker (nevise_titles_wrongs, nevise_titles_corrects, nevise_titles_paknevis, ['Nevise-news-titles-539', 'Paknevis'])\n",
        "eval_nevise_titles_nevise = eval_spell_checker (nevise_titles_wrongs, nevise_titles_corrects, nevise_titles_nevise, ['Nevise-news-titles-539', 'Nevise2'])\n",
        "eval_nevise_titles_nevise_v1 = eval_spell_checker (nevise_titles_wrongs, nevise_titles_corrects, nevise_titles_nevise_v1, ['nevise-news-title-539', 'nevise-v1'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60afd26f-3655-4918-d25f-608c2681bb84",
        "id": "IFeoaeb5mWwB"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Paknevis on Nevise-news-titles\n",
            "wrong detection rate:0.7802 \twrong correction rate:0.6458 \tcorrect to wrong rate:0.0235 \tprecision:0.777\n",
            "{'wrong': 18365, 'not_detected': 4037, 'detected': 14328, 'c2w': 4112, 'w2c': 11861, 'c2c': 170557}\n",
            "\n",
            "Nevise2 on Nevise-news-titles\n",
            "wrong detection rate:0.828 \twrong correction rate:0.7102 \tcorrect to wrong rate:0.0086 \tprecision:0.9083\n",
            "{'wrong': 18368, 'not_detected': 3160, 'detected': 15208, 'c2w': 1536, 'w2c': 13045, 'c2c': 176100}\n"
          ]
        }
      ],
      "source": [
        "# Result on nevise news title\n",
        "\n",
        "eval_nevise_titles_all_paknevis = eval_spell_checker (nevise_titles_all_wrongs, nevise_titles_all_corrects, nevise_titles_all_paknevis, ['Nevise-news-titles', 'Paknevis'])\n",
        "eval_nevise_titles_all_nevise = eval_spell_checker (nevise_titles_all_wrongs, nevise_titles_all_corrects, nevise_titles_all_nevise, ['Nevise-news-titles', 'Nevise2'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Persian Spell checkers comparison.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}